{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPknzTiqCOIthe1lb8Md2xm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anishasingh23/wikipediaArticleSummary/blob/main/wikipedia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Wikipedia**"
      ],
      "metadata": {
        "id": "QNX-ijDk4Oip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok wikipedia-api transformers plotly requests pillow numpy scikit-learn"
      ],
      "metadata": {
        "id": "FmWE882K4TSj",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5059fc6-e0b5-4dbd-9beb-7aabac0eb535"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.33.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=9d9127d365d9091fc6dceeecf296a55b8d03288916afe8fd2edf8416772d3792\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: watchdog, pyngrok, wikipedia-api, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.3 streamlit-1.44.1 watchdog-6.0.0 wikipedia-api-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile wiki_app_advanced.py\n",
        "# import streamlit as st\n",
        "# import wikipediaapi\n",
        "# import plotly.express as px\n",
        "# from transformers import BertTokenizer, BertModel\n",
        "# import numpy as np\n",
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# from PIL import Image\n",
        "# import requests\n",
        "# from io import BytesIO\n",
        "\n",
        "# # --- Initialize Models with Caching ---\n",
        "# @st.cache_resource\n",
        "# def load_models():\n",
        "#     tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#     model = BertModel.from_pretrained('bert-base-uncased')\n",
        "#     return tokenizer, model\n",
        "\n",
        "# tokenizer, model = load_models()\n",
        "\n",
        "# def get_bert_embedding(text):\n",
        "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "#     outputs = model(**inputs)\n",
        "#     return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
        "\n",
        "# # --- Enhanced UI ---\n",
        "# st.set_page_config(layout=\"wide\")\n",
        "# st.title(\"üåê Wikipedia Semantic Explorer\")\n",
        "\n",
        "# # --- Search & Display Logic ---\n",
        "# wiki = wikipediaapi.Wikipedia(\n",
        "#     language=\"en\",\n",
        "#     user_agent=\"MyApp/1.0\"\n",
        "# )\n",
        "\n",
        "# query = st.text_input(\"**Search Wikipedia**\", \"Artificial Intelligence\")\n",
        "\n",
        "# if query:\n",
        "#     with st.spinner(\"Fetching and analyzing...\"):\n",
        "#         page = wiki.page(query)\n",
        "#         if page.exists():\n",
        "#             col1, col2 = st.columns([2, 1])\n",
        "\n",
        "#             with col1:\n",
        "#                 st.subheader(f\"üìñ {page.title}\")\n",
        "#                 st.markdown(page.summary[:1000])\n",
        "\n",
        "#                 # Related articles\n",
        "#                 try:\n",
        "#                     links = list(page.links.keys())[:5]\n",
        "#                     embeddings = np.array([get_bert_embedding(link) for link in [query] + links])\n",
        "#                     similarities = cosine_similarity(embeddings[0:1], embeddings[1:])[0]\n",
        "\n",
        "#                     st.subheader(\"üîó Top Related Articles\")\n",
        "#                     for link, score in zip(links, similarities):\n",
        "#                         st.write(f\"- {link} (Relevance: {score:.2f})\")\n",
        "#                 except Exception as e:\n",
        "#                     st.error(f\"Similarity calculation failed: {str(e)}\")\n",
        "\n",
        "#             with col2:\n",
        "#                 # Fixed image handling\n",
        "#                 try:\n",
        "#                     # Get image URL from Wikipedia API differently\n",
        "#                     image_url = f\"https://en.wikipedia.org/w/api.php?action=query&titles={query}&prop=pageimages&format=json&pithumbsize=300\"\n",
        "#                     response = requests.get(image_url).json()\n",
        "#                     pages = response.get('query', {}).get('pages', {})\n",
        "#                     thumbnail = next(iter(pages.values())).get('thumbnail', {}).get('source')\n",
        "\n",
        "#                     if thumbnail:\n",
        "#                         img_response = requests.get(thumbnail)\n",
        "#                         img = Image.open(BytesIO(img_response.content))\n",
        "#                         st.image(img, caption=page.title, use_column_width=True)\n",
        "#                     else:\n",
        "#                         st.info(\"No image available for this page\")\n",
        "#                 except Exception as e:\n",
        "#                     st.warning(f\"Couldn't load image: {str(e)}\")\n",
        "\n",
        "#                 # Similarity graph\n",
        "#                 if 'similarities' in locals():\n",
        "#                     fig = px.bar(x=links, y=similarities,\n",
        "#                                 title=\"Semantic Similarity Scores\",\n",
        "#                                 labels={'x': 'Article', 'y': 'Relevance'})\n",
        "#                     st.plotly_chart(fig)\n",
        "\n",
        "#         else:\n",
        "#             st.error(\"Page not found. Try another search term.\")"
      ],
      "metadata": {
        "id": "si0PUlwO4PX0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile wiki_app_advanced.py\n",
        "import streamlit as st\n",
        "\n",
        "# MUST be the first Streamlit command\n",
        "st.set_page_config(\n",
        "    layout=\"wide\",\n",
        "    page_title=\"üåê Wikipedia Semantic Explorer+\",\n",
        "    page_icon=\"üîç\"\n",
        ")\n",
        "\n",
        "# Now import other libraries\n",
        "import wikipediaapi\n",
        "import plotly.express as px\n",
        "from transformers import BertTokenizer, BertModel, pipeline\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import time\n",
        "\n",
        "# --- Custom CSS ---\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".article-card {\n",
        "    border: 1px solid #e0e0e0;\n",
        "    border-radius: 10px;\n",
        "    padding: 15px;\n",
        "    margin: 10px 0;\n",
        "    transition: box-shadow 0.3s;\n",
        "}\n",
        ".article-card:hover {\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# --- Initialize Models with Caching ---\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    return tokenizer, model, summarizer\n",
        "\n",
        "tokenizer, model, summarizer = load_models()\n",
        "\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
        "\n",
        "# --- Main App ---\n",
        "st.title(\"üåê Wikipedia Semantic Explorer+\")\n",
        "\n",
        "# --- Search & Display Logic ---\n",
        "wiki = wikipediaapi.Wikipedia(\n",
        "    language=\"en\",\n",
        "    user_agent=\"WikiExplorer/1.0\"\n",
        ")\n",
        "\n",
        "query = st.text_input(\"**Search Wikipedia**\", \"Artificial Intelligence\",\n",
        "                    help=\"Try 'Machine Learning' or 'Quantum Computing'\")\n",
        "\n",
        "if query:\n",
        "    with st.spinner(\"üîç Fetching and analyzing content...\"):\n",
        "        start_time = time.time()\n",
        "        page = wiki.page(query)\n",
        "\n",
        "        if page.exists():\n",
        "            col1, col2 = st.columns([2, 1])\n",
        "\n",
        "            with col1:\n",
        "                # Article Header with Link\n",
        "                st.subheader(f\"üìñ [{page.title}](https://en.wikipedia.org/wiki/{page.title.replace(' ', '_')})\")\n",
        "\n",
        "                # Summary with Read More toggle\n",
        "                with st.expander(\"Show Summary\", expanded=True):\n",
        "                    summary = page.summary[:1500]\n",
        "                    st.markdown(summary)\n",
        "\n",
        "                # Related Articles Section\n",
        "                st.subheader(\"üîó Top Related Articles\")\n",
        "                links = list(page.links.keys())[:8]\n",
        "\n",
        "                try:\n",
        "                    embeddings = np.array([get_bert_embedding(link) for link in [query] + links])\n",
        "                    similarities = cosine_similarity(embeddings[0:1], embeddings[1:])[0]\n",
        "\n",
        "                    for link, score in sorted(zip(links, similarities), key=lambda x: -x[1])[:5]:\n",
        "                        related_page = wiki.page(link)\n",
        "                        if related_page.exists():\n",
        "                            with st.container():\n",
        "                                st.markdown(f\"\"\"\n",
        "                                <div class=\"article-card\">\n",
        "                                    <h4><a href=\"https://en.wikipedia.org/wiki/{link.replace(' ', '_')}\" target=\"_blank\">{link}</a> (Relevance: {score:.2f})</h4>\n",
        "                                    <p>{related_page.summary[:200]}...</p>\n",
        "                                </div>\n",
        "                                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Similarity calculation failed: {str(e)}\")\n",
        "\n",
        "            with col2:\n",
        "                # Image and Quick Facts\n",
        "                try:\n",
        "                    image_url = f\"https://en.wikipedia.org/w/api.php?action=query&titles={query}&prop=pageimages&format=json&pithumbsize=400\"\n",
        "                    response = requests.get(image_url, timeout=5).json()\n",
        "                    thumbnail = next(iter(response['query']['pages'].values())).get('thumbnail', {}).get('source')\n",
        "\n",
        "                    if thumbnail:\n",
        "                        img_response = requests.get(thumbnail, timeout=5)\n",
        "                        img = Image.open(BytesIO(img_response.content))\n",
        "                        st.image(img, caption=page.title, use_column_width=True)\n",
        "                    else:\n",
        "                        st.info(\"üé® No preview image available\")\n",
        "                except:\n",
        "                    st.warning(\"‚ö†Ô∏è Couldn't load image\")\n",
        "\n",
        "                with st.expander(\"‚ö° Quick Facts\"):\n",
        "                    first_section = next(iter(page.sections.values()), None)\n",
        "                    if first_section:\n",
        "                        st.write(first_section.text[:500])\n",
        "                    else:\n",
        "                        st.write(\"No quick facts available\")\n",
        "\n",
        "                if 'similarities' in locals():\n",
        "                    fig = px.bar(\n",
        "                        x=[link[:20] + \"...\" for link in links[:5]],\n",
        "                        y=similarities[:5],\n",
        "                        title=\"üìä Semantic Similarity\",\n",
        "                        labels={'x': 'Article', 'y': 'Relevance Score'},\n",
        "                        color=similarities[:5],\n",
        "                        color_continuous_scale='Teal'\n",
        "                    )\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            st.caption(f\"‚è±Ô∏è Generated in {time.time() - start_time:.2f} seconds | üìù {len(page.summary)} characters | üîó {len(links)} related articles\")\n",
        "\n",
        "        else:\n",
        "            st.error(\"‚ùå Page not found. Try another search term.\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Built with ‚ô• using Wikipedia API, BERT, and Streamlit\")"
      ],
      "metadata": {
        "id": "OJQZYv1FA2Lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5124051-5321-488f-dd53-d0b77e0d85d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing wiki_app_advanced.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile wiki_app_advanced.py\n",
        "import streamlit as st\n",
        "\n",
        "# MUST be the first Streamlit command\n",
        "st.set_page_config(\n",
        "    layout=\"wide\",\n",
        "    page_title=\"üåê Wikipedia Semantic Explorer+\",\n",
        "    page_icon=\"üîç\"\n",
        ")\n",
        "\n",
        "# Now import other libraries\n",
        "import wikipediaapi\n",
        "import plotly.express as px\n",
        "from transformers import BertTokenizer, BertModel, pipeline\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import time\n",
        "\n",
        "# --- Custom CSS ---\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".article-card {\n",
        "    border: 1px solid #e0e0e0;\n",
        "    border-radius: 10px;\n",
        "    padding: 15px;\n",
        "    margin: 10px 0;\n",
        "    transition: box-shadow 0.3s;\n",
        "}\n",
        ".article-card:hover {\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# --- Initialize Models with Caching ---\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    return tokenizer, model, summarizer\n",
        "\n",
        "tokenizer, model, summarizer = load_models()\n",
        "\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
        "\n",
        "# --- Main App ---\n",
        "st.title(\"üåê Wikipedia Semantic Explorer+\")\n",
        "\n",
        "# --- Search & Display Logic ---\n",
        "wiki = wikipediaapi.Wikipedia(\n",
        "    language=\"en\",\n",
        "    user_agent=\"WikiExplorer/1.0 (contact@example.com)\"\n",
        ")\n",
        "\n",
        "query = st.text_input(\"**Search Wikipedia**\", \"Artificial Intelligence\",\n",
        "                    help=\"Try 'Machine Learning' or 'Quantum Computing'\")\n",
        "\n",
        "if query:\n",
        "    with st.spinner(\"üîç Fetching and analyzing content...\"):\n",
        "        start_time = time.time()\n",
        "        page = wiki.page(query)\n",
        "\n",
        "        if page.exists():\n",
        "            col1, col2 = st.columns([2, 1])\n",
        "\n",
        "            with col1:\n",
        "                # Article Header with Link\n",
        "                st.subheader(f\"üìñ [{page.title}](https://en.wikipedia.org/wiki/{page.title.replace(' ', '_')})\")\n",
        "\n",
        "                # Summary with Read More toggle\n",
        "                with st.expander(\"Show Summary\", expanded=True):\n",
        "                    summary = page.summary[:1500]\n",
        "                    st.markdown(summary)\n",
        "\n",
        "                # Related Articles Section\n",
        "                st.subheader(\"üîó Top Related Articles\")\n",
        "                links = list(page.links.keys())[:8]\n",
        "\n",
        "                try:\n",
        "                    embeddings = np.array([get_bert_embedding(link) for link in [query] + links])\n",
        "                    similarities = cosine_similarity(embeddings[0:1], embeddings[1:])[0]\n",
        "\n",
        "                    for link, score in sorted(zip(links, similarities), key=lambda x: -x[1])[:5]:\n",
        "                        related_page = wiki.page(link)\n",
        "                        if related_page.exists():\n",
        "                            with st.container():\n",
        "                                st.markdown(f\"\"\"\n",
        "                                <div class=\"article-card\">\n",
        "                                    <h4><a href=\"https://en.wikipedia.org/wiki/{link.replace(' ', '_')}\" target=\"_blank\">{link}</a> (Relevance: {score:.2f})</h4>\n",
        "                                    <p>{related_page.summary[:200]}...</p>\n",
        "                                </div>\n",
        "                                \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Similarity calculation failed: {str(e)}\")\n",
        "\n",
        "            with col2:\n",
        "                # Image and Quick Facts\n",
        "                try:\n",
        "                    image_url = f\"https://en.wikipedia.org/w/api.php?action=query&titles={query}&prop=pageimages&format=json&pithumbsize=400\"\n",
        "                    response = requests.get(image_url, timeout=5).json()\n",
        "                    thumbnail = next(iter(response['query']['pages'].values())).get('thumbnail', {}).get('source')\n",
        "\n",
        "                    if thumbnail:\n",
        "                        img_response = requests.get(thumbnail, timeout=5)\n",
        "                        img = Image.open(BytesIO(img_response.content))\n",
        "                        st.image(img, caption=page.title, use_column_width=True)\n",
        "                    else:\n",
        "                        st.info(\"üé® No preview image available\")\n",
        "                except:\n",
        "                    st.warning(\"‚ö†Ô∏è Couldn't load image\")\n",
        "\n",
        "                with st.expander(\"‚ö° Quick Facts\"):\n",
        "                    if page.sections:  # Now checking if sections exist (it's a list)\n",
        "                        first_section = page.sections[0] if len(page.sections) > 0 else None\n",
        "                        if first_section:\n",
        "                            st.write(first_section.text[:500])\n",
        "                        else:\n",
        "                            st.write(\"No quick facts available\")\n",
        "\n",
        "                if 'similarities' in locals():\n",
        "                    fig = px.bar(\n",
        "                        x=[link[:20] + \"...\" for link in links[:5]],\n",
        "                        y=similarities[:5],\n",
        "                        title=\"üìä Semantic Similarity\",\n",
        "                        labels={'x': 'Article', 'y': 'Relevance Score'},\n",
        "                        color=similarities[:5],\n",
        "                        color_continuous_scale='Teal'\n",
        "                    )\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            st.caption(f\"‚è±Ô∏è Generated in {time.time() - start_time:.2f} seconds | üìù {len(page.summary)} characters | üîó {len(links)} related articles\")\n",
        "\n",
        "        else:\n",
        "            st.error(\"‚ùå Page not found. Try another search term.\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Built with ‚ô• using Wikipedia API, BERT, and Streamlit\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1n1TKuwIxZa",
        "outputId": "8c0355ab-c475-4c11-915d-1f17f0c2a151"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting wiki_app_advanced.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n"
      ],
      "metadata": {
        "id": "y8Xp52-P_A3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ec96bf-b160-44e6-f667-04ad0979c58b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cleanup\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "ngrok.kill()\n",
        "os.system('pkill ngrok')  # Force kill any lingering processes\n",
        "\n",
        "# 2. Restart\n",
        "ngrok.set_auth_token(\"2vbuJtKmjEPjgnqYitA5hA8QKmR_776hVR3ruaifkgxMapJDg\")\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print(f\"üöÄ Fresh tunnel: {public_url}\")\n",
        "!streamlit run wiki_app_advanced.py --server.port 8501 &>/dev/null &"
      ],
      "metadata": {
        "id": "4RZ_eTF5-5IB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426e2493-d63e-42dc-ede4-662779826f07"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Fresh tunnel: NgrokTunnel: \"https://b7af-104-196-194-229.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit wikipedia-api transformers plotly requests pillow numpy scikit-learn\n",
        "!streamlit run wiki_app_advanced.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc0SDEEI5v0l",
        "outputId": "591ff721-8b78-4fa2-a9cd-c203a5310bcb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.33.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.196.194.229:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in atexit callback: <function shutdown at 0x7be946dfd440>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 2185, in shutdown\n",
            "    h.flush()\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1093, in flush\n",
            "    if self.stream and hasattr(self.stream, \"flush\"):\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/server.py\", line 470, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/runtime.py\", line 337, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 807, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 520, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B0cuQxdfCUPB"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}